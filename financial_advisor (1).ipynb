{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LLM + RAG Projects on Finance Domain"
      ],
      "metadata": {
        "id": "saANq6XLdbIX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1Kt2Ge7c6zQ"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from urllib.request import urlopen\n",
        "except ImportError:\n",
        "    from urllib2 import urlopen\n",
        "\n",
        "import certifi\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_jsonparsed_data(url, api_key, exchange):\n",
        "  if exchange == \"NSE\":\n",
        "    url = f\"https://financialmodelingprep.com/api/v3/search?query={ticker}&exchange=NSE&apikey={api_key}\"\n",
        "  else:\n",
        "    url = f\"https://financialmodelingprep.com/api/v3/quote/{ticker}?apikey={api_key}\"\n",
        "  response = urlopen(url, cafile=certifi.where())\n",
        "  data = response.read().decode(\"utf-8\")\n",
        "  return json.loads(data)\n",
        "\n",
        "api_key=\"C1HRSweTniWdBuLmTTse9w8KpkoiouM5\"\n",
        "ticker = \"MSFT\"\n",
        "exchange = \"US\"\n",
        "eco_ind = pd.DataFrame(get_jsonparsed_data(ticker, api_key,exchange))\n",
        "eco_ind"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the Langchain Libraries"
      ],
      "metadata": {
        "id": "3NvuSNITdq7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community langchain-core transformers"
      ],
      "metadata": {
        "id": "u8GxUu7Qdo17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_economic_data(df):\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['earningsAnnouncement'] = pd.to_datetime(df['earningsAnnouncement'])\n",
        "    return df\n",
        "\n",
        "preprocessed_economic_df = preprocess_economic_data(eco_ind)\n",
        "preprocessed_economic_df"
      ],
      "metadata": {
        "id": "ynpXvIMpdvdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing the Pre-Processed Data into CSV\n"
      ],
      "metadata": {
        "id": "rnTCjFWed1vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_economic_df.to_csv(\"eco_ind.csv\")"
      ],
      "metadata": {
        "id": "S6XNd72rd4xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the Hugging Face Embedding Library"
      ],
      "metadata": {
        "id": "X8kwAqi6eCWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  langchain sentence_transformers"
      ],
      "metadata": {
        "id": "241_-ioYeICt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "hg_embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "EYVjFr5lejGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "loader_eco = CSVLoader('eco_ind.csv')\n",
        "documents_eco = loader_eco.load()\n",
        "\n",
        "# Get your splitter ready\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=5)\n",
        "\n",
        "# Split your docs into texts\n",
        "texts_eco = text_splitter.split_documents(documents_eco)\n",
        "\n",
        "# Embeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "yV7VC7TdelBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Vector DB for RAG"
      ],
      "metadata": {
        "id": "0jpFb-qhemo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "persist_directory = 'docs/chroma_rag/'"
      ],
      "metadata": {
        "id": "Ym5TXUlxesUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "economic_langchain_chroma = Chroma.from_documents(\n",
        "    documents=texts_eco,\n",
        "    collection_name=\"economic_data\",\n",
        "    embedding=hg_embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "4Tpv-46Deugp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Microsoft(MSFT)\"\n",
        "docs_eco = economic_langchain_chroma.similarity_search(question,k=3)"
      ],
      "metadata": {
        "id": "uPJmDZceexZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building RAG Chain using Vector DB and LLM"
      ],
      "metadata": {
        "id": "3alwH06qe1CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import HuggingFaceHub\n",
        "from IPython.display import display, Markdown\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"tiiuae/falcon-7b-instruct\",\n",
        "    model_kwargs={\"temperature\": 0.1},\n",
        ")\n",
        "\n",
        "retriever_eco = economic_langchain_chroma.as_retriever(search_kwargs={\"k\":2})\n",
        "qs=\"Microsoft(MSFT) Financial Report\"\n",
        "template = \"\"\"You are a Financial Market Expert and Get the Market Economic Data and Market News about Company and Build the Financial Report for me.\n",
        "              Understand this Market Information {context} and Answer the Query for this Company {question}. i just need the data into Tabular Form as well.\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(input_variables=[\"context\",\"question\"], template=template)\n",
        "qa_with_sources = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",chain_type_kwargs = {\"prompt\": PROMPT}, retriever=retriever_eco, return_source_documents=True)\n",
        "llm_response = qa_with_sources({\"query\": qs})"
      ],
      "metadata": {
        "id": "C6oUMRJMe3ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(llm_response['result'])"
      ],
      "metadata": {
        "id": "mc7GiPA9e53n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using NEWS API to Build Financial News Summarizer about the Company Sentiment in Current Time"
      ],
      "metadata": {
        "id": "XjIgtKFze-LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from newsapi import NewsApiClient\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def fetch_news(query, from_date, to_date, language='en', sort_by='relevancy', page_size=30, api_key='YOUR_API_KEY'):\n",
        "    # Initialize the NewsAPI client\n",
        "    newsapi = NewsApiClient(api_key=api_key)\n",
        "    query = query.replace(' ','&')\n",
        "    # Fetch all articles matching the query\n",
        "    all_articles = newsapi.get_everything(\n",
        "        q=query,\n",
        "        from_param=from_date,\n",
        "        to=to_date,\n",
        "        language=language,\n",
        "        sort_by=sort_by,\n",
        "        page_size=page_size\n",
        "    )\n",
        "\n",
        "    # Extract articles\n",
        "    articles = all_articles.get('articles', [])\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    if articles:\n",
        "        df = pd.DataFrame(articles)\n",
        "        return df\n",
        "    else:\n",
        "        return pd.DataFrame()  # Return an empty DataFrame if no articles are found\n",
        "\n",
        "# Get the current time\n",
        "current_time = datetime.now()\n",
        "# Get the time 10 days ago\n",
        "time_10_days_ago = current_time - timedelta(days=10)\n",
        "api_key = 'c0e23a8956cf4b54af382abd932f88ff'\n",
        "q = \"Microsoft News June 2024\"\n",
        "df = fetch_news(q, time_10_days_ago, current_time, api_key=api_key)\n",
        "\n",
        "df_news = df.drop(\"source\", axis=1)\n",
        "\n",
        "def preprocess_news_data(df):\n",
        "    # Convert publishedAt to datetime\n",
        "    df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n",
        "    df = df[~df['author'].isna()]\n",
        "    df = df[['author', 'title']]\n",
        "    return df\n",
        "\n",
        "preprocessed_news_df = preprocess_news_data(df_news)\n",
        "preprocessed_news_df.head()"
      ],
      "metadata": {
        "id": "GnSMdhbbfCGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processing the Data"
      ],
      "metadata": {
        "id": "xPBDbzJTfGhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_prompt(news_df):\n",
        "    prompt = \"You are a financial analyst tasked with providing insights into recent news articles related to the financial industry. Here are some recent news articles:\\n\\n\"\n",
        "\n",
        "    for index, row in news_df.iterrows():\n",
        "        title = row['title']\n",
        "        prompt += f\"   **News:** {title}\\n\\n\"\n",
        "\n",
        "    prompt += \"Please analyze these articles and provide insights into any potential impacts on the financial industry Sentiment on the provided company.\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Build the prompt\n",
        "prompt = build_prompt(preprocessed_news_df)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "XvNhJrenfJ8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM from Hugging Face Open Source"
      ],
      "metadata": {
        "id": "nZf8YkBWfMfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceHub(\n",
        "    repo_id=\"tiiuae/falcon-7b-instruct\",\n",
        "    model_kwargs={\"temperature\": 0.1},\n",
        ")"
      ],
      "metadata": {
        "id": "0qI77dFOfQ4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(llm.invoke(prompt))"
      ],
      "metadata": {
        "id": "c7BdLMt_fTP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Financial Data Investment Advisor:\n",
        "Loading the Financial Data from Kaggle or Any Open Source Platform"
      ],
      "metadata": {
        "id": "2xx6Xm0IfVyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Finance_data.csv\")\n",
        "data_fin = data.to_dict(orient='records')"
      ],
      "metadata": {
        "id": "qm09pYECfYUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for entry in data_fin:\n",
        "  prompt = f\"I'm a {entry['age']}-year-old {entry['gender']} looking to invest in {entry['Avenue']} for {entry['Purpose']} over the next {entry['Duration']}. What are my options?\"\n",
        "  print(prompt)"
      ],
      "metadata": {
        "id": "GH71eX1Qfik0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processng the Data into Prompt-Response Format"
      ],
      "metadata": {
        "id": "B9Kk7dCdfnS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to prompt-response format\n",
        "prompt_response_data = []\n",
        "for entry in data_fin:\n",
        "    prompt = f\"I'm a {entry['age']}-year-old {entry['gender']} looking to invest in {entry['Avenue']} for {entry['Purpose']} over the next {entry['Duration']}. What are my options?\"\n",
        "    response = (\n",
        "        f\"Based on your preferences, here are your investment options:\\n\"\n",
        "        f\"- Mutual Funds: {entry['Mutual_Funds']}\\n\"\n",
        "        f\"- Equity Market: {entry['Equity_Market']}\\n\"\n",
        "        f\"- Debentures: {entry['Debentures']}\\n\"\n",
        "        f\"- Government Bonds: {entry['Government_Bonds']}\\n\"\n",
        "        f\"- Fixed Deposits: {entry['Fixed_Deposits']}\\n\"\n",
        "        f\"- PPF: {entry['PPF']}\\n\"\n",
        "        f\"- Gold: {entry['Gold']}\\n\"\n",
        "        f\"Factors considered: {entry['Factor']}\\n\"\n",
        "        f\"Objective: {entry['Objective']}\\n\"\n",
        "        f\"Expected returns: {entry['Expect']}\\n\"\n",
        "        f\"Investment monitoring: {entry['Invest_Monitor']}\\n\"\n",
        "        f\"Reasons for choices:\\n\"\n",
        "        f\"- Equity: {entry['Reason_Equity']}\\n\"\n",
        "        f\"- Mutual Funds: {entry['Reason_Mutual']}\\n\"\n",
        "        f\"- Bonds: {entry['Reason_Bonds']}\\n\"\n",
        "        f\"- Fixed Deposits: {entry['Reason_FD']}\\n\"\n",
        "        f\"Source of information: {entry['Source']}\\n\"\n",
        "    )\n",
        "    prompt_response_data.append({\"prompt\": prompt, \"response\": response})\n",
        "\n",
        "prompt_response_data[:5]"
      ],
      "metadata": {
        "id": "2V9QmvQafqLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Storing Data into Vector DB"
      ],
      "metadata": {
        "id": "dl9NNzs2fuP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "documents = []\n",
        "for entry in prompt_response_data:\n",
        "    combined_text = f\"Prompt: {entry['prompt']}\\nResponse: {entry['response']}\"\n",
        "    documents.append(Document(page_content=combined_text))"
      ],
      "metadata": {
        "id": "iXwItqpDfxNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "TZ_DRMBxfza9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "persist_directory = 'docs/chroma/'\n",
        "vectordb_fin = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=hg_embeddings,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ],
      "metadata": {
        "id": "H3e8YGwdf2oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building RAG System using VectorDB and LLM"
      ],
      "metadata": {
        "id": "vBJwVqTuf5Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "retriever_fin = vectordb_fin.as_retriever(search_kwargs={\"k\":5})\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=retriever_fin, return_source_documents=False)\n",
        "query = \"I'm a 34-year-old female looking to invest in mutual funds for wealth creation over the next 1-3 years. What are my options?\"\n",
        "result = qa({\"query\": query})\n",
        "result"
      ],
      "metadata": {
        "id": "tBEuZ6ogf_aj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}